{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from accelerate import dispatch_model\n",
    "from accelerate.utils import infer_auto_device_map\n",
    "import accelerate\n",
    "\n",
    "model_name = \"model/Qwen2.5-Coder-3B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "write a quick sort algorithm.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "prompt = \"write a quick sort algorithm.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,   4934,    264,   3974,\n",
      "           3378,  12111,     13, 151645,    198, 151644,  77091,    198]],\n",
      "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "print(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,   4934,    264,   3974,\n",
      "           3378,  12111,     13, 151645,    198, 151644,  77091,    198,  95456,\n",
      "              0,  21193,    374,    264,  13027,   8129,    315,    279,  17251,\n",
      "          15967,  12111,   1447,  73594,  12669,    198,    750,   3974,  18435,\n",
      "          10939,    982,    262,    421,   2422,  10939,      8,   2651,    220,\n",
      "             16,    510,    286,    470,   2890,    198,    262,    770,    510,\n",
      "            286,  26045,    284,   2890,  24693,  10939,      8,    442,    220,\n",
      "             17,    921,    286,   2115,    284,    508,     87,    369,    856,\n",
      "            304,   2890,    421,    856,    366,  26045,    921,    286,   6149,\n",
      "            284,    508,     87,    369,    856,    304,   2890,    421,    856,\n",
      "            621,  26045,    921,    286,   1290,    284,    508,     87,    369,\n",
      "            856,    304,   2890,    421,    856,    861,  26045,    921,    286,\n",
      "            470,   3974,  18435,  17671,      8,    488,   6149,    488,   3974,\n",
      "          18435,  27704,    692,      2,  13383,  10431,    510,   1118,    284,\n",
      "            508,     18,     11,    220,     21,     11,    220,     23,     11,\n",
      "            220,     16,     15,     11,    220,     16,     11,    220,     17,\n",
      "             11,    220,     16,    921,  28298,  11210,    284,   3974,  18435,\n",
      "          10939,    340,   1350,  44386,  11210,    340,  13874,  19324,  14374,\n",
      "          71287,    510,     16,     13,   3070,   3978,  11538,  95518,   1416,\n",
      "            279,   1334,    702,    220,     15,    476,    220,     16,   2392,\n",
      "             11,    432,    374,   2669,  10615,     11,    773,    582,    470,\n",
      "            432,    438,    374,    624,     17,     13,   3070,     47,  16084,\n",
      "          24145,  95518,   1205,   5157,    279,   6149,   2392,    315,    279,\n",
      "           1334,    438,    279,  26045,     13,   1096,    646,    387,   2814,\n",
      "           1667,   1565,   1118,  24693,  10939,      8,    442,    220,     17,\n",
      "             60,  18639,     18,     13,   3070,  49978,    287,    334,    510,\n",
      "            256,    481,   1205,   1855,   2326,  11469,     25,   1565,   2359,\n",
      "             63,    369,   5424,   2686,   1091,    279,  26045,     11,   1565,\n",
      "          19656,     63,    369,   5424,   6144,    311,    279,  26045,     11,\n",
      "            323,   1565,   1291,     63,    369,   5424,   7046,   1091,    279,\n",
      "          26045,    624,     19,     13,   3070,  78542,  77143,  95518,   1205,\n",
      "          52847,   3796,    279,   1565,  27763,  18435,     63,    729,    311,\n",
      "            279,   1565,   2359,     63,    323,   1565,   1291,     63,  11469,\n",
      "            624,     20,     13,   3070,  78440,    268,    367,  95518,  17375,\n",
      "             11,    582,  77784,    279,  10615,   1565,   2359,     63,   1140,\n",
      "             11,    279,   1565,  19656,     63,   1140,     11,    323,    279,\n",
      "          10615,   1565,   1291,     63,   1140,    311,    633,    279,  10615,\n",
      "           1334,    382,   1986,   8129,   5711,   1140,  12674,   4664,    311,\n",
      "          16658,    279,   1334,     11,   3259,    432,  63594,     13,   4354,\n",
      "             11,   2506,    304,   3971,    429,    419,   8129,    374,    537,\n",
      "            279,   1429,  11050,    304,   3793,    315,   3550,  23094,   4152,\n",
      "            311,    279,    990,    315,   5107,  11469,     13,   1752,    458,\n",
      "            304,  41661,   2319,     11,    498,   2578,   1366,    311,   4211,\n",
      "            279,  17251,  15967,  12111,   1667,    264,   2155,   5486,     13,\n",
      "         151645]], device='mps:0')\n",
      "tensor([[151644,   8948,    198,   2610,    525,   1207,  16948,     11,   3465,\n",
      "            553,  54364,  14817,     13,   1446,    525,    264,  10950,  17847,\n",
      "             13, 151645,    198, 151644,    872,    198,   4934,    264,   3974,\n",
      "           3378,  12111,     13, 151645,    198, 151644,  77091,    198]],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

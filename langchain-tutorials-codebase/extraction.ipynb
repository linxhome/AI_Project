{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Extraction Chain\n",
    "\n",
    " - use tool-calling features of chat models to extract structured information from unstructured text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content=\"You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Alan Smith is 6 feet tall and has blond hair.', additional_kwargs={}, response_metadata={})]\n",
      "name='Alan Smith' hair_color='blond' height_in_meters='1.83'\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
    "    hair_color: Optional[str] = Field(\n",
    "        default=None, description=\"The color of the person's hair if known\"\n",
    "    )\n",
    "    height_in_meters: Optional[str] = Field(\n",
    "        default=None, description=\"Height measured in meters\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",\n",
    "        ),\n",
    "        # Please see the how-to about improving performance with\n",
    "        # reference examples.\n",
    "        # MessagesPlaceholder('examples'),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "import os\n",
    "# è®¾ç½® OpenAI API å¯†é’¥\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "structured_llm = llm.with_structured_output(Person)\n",
    "text = \"Alan Smith is 6 feet tall and has blond hair.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "print(prompt)\n",
    "\n",
    "result = structured_llm.invoke(prompt)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people=[Person(name='Jeff', hair_color='black', height_in_meters='1.83'), Person(name='Anna', hair_color='black', height_in_meters=None)]\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "class PersonList(BaseModel):\n",
    "    people:List[Person]\n",
    "\n",
    "structured_llm = llm.with_structured_output(schema=PersonList)\n",
    "text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
    "prompt = prompt_template.invoke({\"text\": text})\n",
    "response = structured_llm.invoke(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"2 ðŸ¦œ 2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
    "    {\"role\": \"user\", \"content\": \"2 ðŸ¦œ 3\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
    "    {\"role\": \"user\", \"content\": \"3 ðŸ¦œ 4\"},\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The ocean is vast and blue. It's more than 20,000 feet deep.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  PersonList (0efda4c9-8a27-43df-a943-9d08fec65140)\n",
      " Call ID: 0efda4c9-8a27-43df-a943-9d08fec65140\n",
      "  Args:\n",
      "    people: []\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "N\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Fiona traveled far from France to Spain.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  PersonList (087eeaae-1270-4945-a5d9-97006653999c)\n",
      " Call ID: 087eeaae-1270-4945-a5d9-97006653999c\n",
      "  Args:\n",
      "    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import tool_example_to_messages\n",
    "\n",
    "examples = [\n",
    "    (\n",
    "        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n",
    "        PersonList(people=[]),\n",
    "    ),\n",
    "    (\n",
    "        \"Fiona traveled far from France to Spain.\",\n",
    "        PersonList(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n",
    "    ),\n",
    "]\n",
    "messages = []\n",
    "\n",
    "for txt,tool_call in examples:\n",
    "    if tool_call.people:\n",
    "        ai_repsonse = \"Detected People.\"\n",
    "    else :\n",
    "        ai_repsonse = \"No people detected.\"\n",
    "    messages.extend(tool_example_to_messages(txt,[tool_call], ai_repsonse))\n",
    "    \n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "people=[Person(name='Luna', hair_color='None', height_in_meters='None'), Person(name='Apollo', hair_color='None', height_in_meters='None'), Person(name='Graviton', hair_color='None', height_in_meters='None')]\n",
      "people=[]\n"
     ]
    }
   ],
   "source": [
    "message_no_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
    "}\n",
    "message_no_extraction = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
    "}\n",
    "\n",
    "structured_llm = llm.with_structured_output(schema=PersonList)\n",
    "print(type(llm))\n",
    "print(type(structured_llm))\n",
    "res = structured_llm.invoke([message_no_extraction])\n",
    "print(res)\n",
    "\n",
    "rest = structured_llm.invoke(messages + [message_no_extraction])\n",
    "print(rest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
